<p>I saw a nice <a href="https://www.figure-eight.com/building-the-software-2-0-stack-by-andrej-karpathy-from-tesla/">talk</a> by Andrej Karpathy about his vision for Software 2.0. The idea is this: while historically software is written by humans, in the future most software may be written by machines. A neural network is a piece of code whose parameters are populated by an optimiser; humans design the architecture (although this will also inevitably be <a href="http://www.fast.ai/2018/07/16/auto-ml2/">automated</a>) and an optimiser modulates the code to achieve an objective.</p>

<p>Karpathy presented the development of computer vision as an example of this trend. In the 1980s, work was done to try and develop a complete ‘stack’ for computer vision: the processes of analysing the image, extracting features, and classifying the contents were formalised and abstracted in the same way as you would break down an engineering problem to build some complex machine.</p>

<p>This led to a lot of work on the individual steps. In the 1990s, a tremendous amount of work went into algorithms to do exactly that, for instance, edge detection, segmentation, and feature extraction. However, the advent of CNNs in the 2010s turned the field on its head: it was now possible to do end-to-end learning to directly achieve objectives such as classification without manual feature engineering. Most of the effort is now focused on collecting balanced, diverse, and informative training data sets, as well as speeding up the training process. Karpathy proposes a ‘Software 2.0 IDE’ which would help people feed the most informative data into these models.</p>

<p>I could not help but wonder if similar approaches would be applied to other fields, in particular synthetic biology. Predicting the behaviour of biological systems is a hard problem, due to their internal complexity. Research in synthetic biology has been focused in part on stripping away the complexity to obtain a more managable system. To understand and engineer the systems, we still require mathematical models, whose identification and validation require iterative design-build-test cycles of experiments, which fortunately are becoming more automated.</p>

<p>Could there be a similar revolution where the models are automatically generated, optimal experiments to discriminate among them determined, and the tests run automatically, without human intervention? The idea is not <a href="new">http://science.sciencemag.org/content/324/5923/81</a></p>
