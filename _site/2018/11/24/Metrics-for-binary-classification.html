

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Metrics for binary classification</title>
    <meta name="description" content="In this tutorial we will look at how to evaluate a classifier. To keep things simple, we won't look at details of the classifier itself, but we'll assume that we already have a working model, and consider how we might evaluate its performance. I'll explain some useful metrics including precision, recall, and the F1 score.">
    <meta name="author" content="Nadanai Laohakunakorn">

    <!-- Enable responsive viewport -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le styles -->
    <link href="/assets/themes/twitter/bootstrap/css/bootstrap.2.2.2.min.css" rel="stylesheet">  
  <!--    <link href="/assets/themes/twitter/bootstrap/css/cosmo.css" rel="stylesheet"> -->
    <link href="/assets/themes/twitter/css/style.css?body=1" rel="stylesheet" type="text/css" media="all">
 <!--   <link href="/assets/themes/twitter/css/kbroman.css" rel="stylesheet" type="text/css" media="all">   -->
    <link href="/assets/themes/twitter/css/nl.css" rel="stylesheet" type="text/css" media="all">

    <!-- Le fav and touch icons -->

    <!-- atom & rss feed -->
    <link href="nil" type="application/atom+xml" rel="alternate" title="Sitewide ATOM Feed">
    <link href="nil" type="application/rss+xml" rel="alternate" title="Sitewide RSS Feed">

  </head>

  <body>
    <div class="navbar">
      <div class="navbar-inner">
        <div class="container-narrow">
          <a class="brand" href="/">Home</a>
          <ul class="nav">
            <li><a href="/pages/tutorials.html">Tutorials</a></li>
            <li><a href="/pages/algorithms.html">Algorithms</a></li>
            <li><a href="/pages/cv.html">CV</a></li>
        </div>
      </div>
    </div>

    <div class="container-narrow">

      <div class="content">
        

<div class="page-header">
  <h1>Metrics for binary classification </h1>
</div>

<div class="row-fluid post-full">
  <div class="span12">
    <div class="date">
      <span>24 November 2018</span>
    </div>
    <div class="content">
      <p>In this tutorial we will look at how to evaluate a classifier. To keep things simple, we won’t look at details of the classifier itself, but we’ll assume that we already have a working model, and consider how we might evaluate its performance. I’ll explain some useful metrics including precision, recall, and the F1 score.</p>

<p>Let’s get started!</p>

<p>The tutorial contains the following sections:</p>

<ul id="markdown-toc">
  <li><a href="#1-binary-classification-and-the-decision-boundary" id="markdown-toc-1-binary-classification-and-the-decision-boundary">1. Binary classification and the decision boundary</a></li>
  <li><a href="#2-metrics-for-model-evaluation" id="markdown-toc-2-metrics-for-model-evaluation">2. Metrics for model evaluation</a>    <ul>
      <li><a href="#21-minimum-error" id="markdown-toc-21-minimum-error">2.1 Minimum error</a></li>
      <li><a href="#22-precision" id="markdown-toc-22-precision">2.2 Precision</a></li>
      <li><a href="#23-recall" id="markdown-toc-23-recall">2.3 Recall</a></li>
      <li><a href="#24-balancing-precision-and-recall-the-f1-metric" id="markdown-toc-24-balancing-precision-and-recall-the-f1-metric">2.4 Balancing precision and recall: the F1 metric</a></li>
      <li><a href="#25-the-roc-curve" id="markdown-toc-25-the-roc-curve">2.5 The ROC curve</a></li>
    </ul>
  </li>
  <li><a href="#3-conclusions" id="markdown-toc-3-conclusions">3. Conclusions</a></li>
</ul>
<!-- toc -->

<hr />

<h3 id="1-binary-classification-and-the-decision-boundary">1. Binary classification and the decision boundary</h3>

<p>To begin, let’s suppose we have some data distributed along a one dimensional coordinate. The data fall into two unequal populations, which we’ll call ‘true’ and ‘false’, and each population is normally distributed about some mean value. Setting the 0 value of our coordinate axis to lie equidistant from the two means, we have the following situation:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Show two normal distributions</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">nsamplestrue</span>  <span class="o">=</span> <span class="mi">2500</span>
<span class="n">nsamplesfalse</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">mean</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">distA</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nsamplestrue</span><span class="p">)</span><span class="o">+</span><span class="n">mean</span>
<span class="n">distB</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nsamplesfalse</span><span class="p">)</span><span class="o">-</span><span class="n">mean</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">distA</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'True'</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">distB</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'False'</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=-</span><span class="n">mean</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Coordinate'</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Counts'</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/MBC_4_0.png" width="50%" alt="me" align="center" hspace="40" vspace="40" /></p>

<p>With these data, a classifier model should predict, given a new data point with some value of the coordinate, whether it belongs to the True or the False population. This type of problem is known as a binary classification, and is extremely common: for example, the two populations could represent the result of a medical test, or the presence of some signal above a noisy background.</p>

<p>An easy way to do this is for the model to determine a ‘decision boundary’ or threshold: points located to the left of the boundary belong to the False category, and those on the right of the boundary belong to True. This is shown below:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Show decision boundary </span>

<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">distA</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'True'</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">distB</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'False'</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=-</span><span class="n">mean</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Boundary'</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Coordinate'</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Counts'</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/MBC_6_0.png" width="50%" alt="me" align="center" hspace="40" vspace="40" /></p>

<p>When we train a model, what we’re doing is letting it come up with the location of this boundary. We’ll leave the discussion of training to another tutorial, but I hope you can already see that different models may come up with different decision boundaries. We can therefore simulate the effects of changing models (or model predictions) by moving the decision boundary around.</p>

<p>The boundary shown here is located exactly in the middle between the two means. While this may seem like a sensible place to put it, it’s not necessarily the optimum location. What does ‘optimum’ mean?</p>

<p>The rest of this tutorial will be devoted to answering that question. In general there is no ‘best’ solution; we can only define objective measures, or metrics, of the model prediction, and then use those measures to compare between different models. Different problems will require prioritising different metrics. Let’s see what this means.</p>

<hr />

<h3 id="2-metrics-for-model-evaluation">2. Metrics for model evaluation</h3>

<h4 id="21-minimum-error">2.1 Minimum error</h4>

<p>In a classification problem, as well as making true positive (TP) and true negative (TN) predictions, a model may also make false positive (FP) and false negative (FN) predictions. In terms of the figure, false positives are orange points located to the right of the decision boundary, while false negatives are blue points to the left.</p>

<p>A useful metric of our model performance might be the total number of false predictions. According to this metric, a more optimal model would be one that we minimises the number of false predictions. The result is shown below, and you can see that the location which minimises the overall error is where the two population distributions cross.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">distA</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">distB</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Coordinate'</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Counts'</span><span class="p">);</span>

<span class="n">decisionboundary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span> <span class="c"># Move the decision boundary around</span>
<span class="n">truepositives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">distA</span> <span class="o">&gt;</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">decisionboundary</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">truenegatives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">distB</span> <span class="o">&lt;</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">decisionboundary</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">falsepositives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">distB</span> <span class="o">&gt;</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">decisionboundary</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">falsenegatives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">distA</span> <span class="o">&lt;</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">decisionboundary</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">falsepreds</span> <span class="o">=</span> <span class="p">(</span><span class="n">falsepositives</span> <span class="o">+</span> <span class="n">falsenegatives</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">decisionboundary</span><span class="p">,</span><span class="n">falsepreds</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Total false </span><span class="se">\n</span><span class="s"> preds'</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">decisionboundary</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">falsepreds</span><span class="p">)],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'r'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">decisionboundary</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">falsepreds</span><span class="p">)],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'r'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Coordinate'</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/MBC_11_0.png" width="500" alt="me" align="center" hspace="40" vspace="40" /></p>

<h4 id="22-precision">2.2 Precision</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">distA</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">distB</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Coordinate'</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Counts'</span><span class="p">);</span>

<span class="n">precision</span> <span class="o">=</span> <span class="n">truepositives</span><span class="o">/</span><span class="p">(</span><span class="n">truepositives</span><span class="o">+</span><span class="n">falsepositives</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">decisionboundary</span><span class="p">,</span><span class="n">precision</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Precision'</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Coordinate'</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'b'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'P = 1'</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'b'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'P = 1'</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span> <span class="p">;</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span> <span class="p">;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/MBC_13_0.png" width="500" alt="me" align="center" hspace="40" vspace="40" /></p>

<p>Minimising the overall error is not necessarily an optimal aim for all situations, however. In an application like email spam detection, for example, if an important email was inadvertently marked as spam, this would be more costly than if a few spam emails got through the filter. We can thus choose a metric which allows us to avoid false positives. The metric which does this determines how many positive predictions are actually correct, and it’s known as ‘precision’:</p>

<p>\begin{equation}
\text{precision}=\frac{TP}{TP + FP} 
\end{equation}</p>

<p>A model which has no false positives at all has a perfect precision value of 1.0. False positives are represented on the graph by the part of the orange distribution which lies to the right of our decision boundary. So, by positioning the decision boundary far to the right, you will ensure that the entire orange distribution lies to the left of the boundary, and so you wil have no false positives at all, and perfect precision.</p>

<p>Of course, moving the boundary further to the right results in a decreasing number of true positives; eventually the model predicts everything as false. Such a model is not useful for classification, but will still have perfect precision. So we can see that the precision metric is not sufficient by itself.</p>

<h4 id="23-recall">2.3 Recall</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">distA</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">distB</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Coordinate'</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Counts'</span><span class="p">);</span>

<span class="n">recall</span> <span class="o">=</span> <span class="n">truepositives</span><span class="o">/</span><span class="p">(</span><span class="n">truepositives</span><span class="o">+</span><span class="n">falsenegatives</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">decisionboundary</span><span class="p">,</span><span class="n">recall</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Recall'</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Coordinate'</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=-</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'g'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'R = 1'</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=-</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'g'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'R = 1'</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> 
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/MBC_16_0.png" width="500" alt="me" align="center" hspace="40" vspace="40" /></p>

<p>The converse of precision is a metric known as ‘recall’, defined as</p>

<p>\begin{equation}
\text{precision}=\frac{TP}{TP + FN} 
\end{equation}</p>

<p>This metric determines the fraction of all true events (the blue distribution) correctly predicted, and thus it favours avoiding false negatives. A situation where false negatives may be dangerous is a medical test, where incorrectly thinking you have a dangerous disease may be less of a worry than incorrectly thinking you don’t have it.</p>

<p>Recall behaves in the opposite way to precision: positioning the decision boundary to the left ensures the entire blue distribution is on the right-hand side of the boundary, giving a perfect recall score of 1.0. Again, the metric is insensitive to how many true negatives you have: if the boundary goes far to the left, and your model always outputs a ‘true’ prediction, you will have perfect recall, but also no true negatives.</p>

<h4 id="24-balancing-precision-and-recall-the-f1-metric">2.4 Balancing precision and recall: the F1 metric</h4>

<p>While both precision (which favours no false positives) and recall (which favours no false negatives) are sometimes useful metrics in their own right, you can see that a more optimal situation might arise when precision and recall are balanced. The geometric mean of the two quantities is known as the F1 metric:</p>

<p>\begin{equation}
\frac{1}{F1}=\frac{1}{2}\left(\frac{1}{\text{Precision}}+\frac{1}{\text{Recall}}\right)
\end{equation}</p>

<p>A maximal F1 score results from both high precision and recall values. It results in a boundary location which is similar to (but not necessarily the same as) the minimium error location.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">distA</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">distB</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Coordinate'</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Counts'</span><span class="p">);</span>

<span class="n">F1</span> <span class="o">=</span> <span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">precision</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="n">recall</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">decisionboundary</span><span class="p">,</span><span class="n">F1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'F1'</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Coordinate'</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">decisionboundary</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">F1</span><span class="p">)],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'m'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Max F1'</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">decisionboundary</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">F1</span><span class="p">)],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'m'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Max F1'</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> 
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="/assets/images/MBC_20_0.png" width="500" alt="me" align="center" hspace="40" vspace="40" /></p>

<h4 id="25-the-roc-curve">2.5 The ROC curve</h4>

<p>A final metric we will look at is a plot of the normalised true positives against false positives. To obtain this curve, we slide the decision boundary from left to right.</p>

<p>At far left values, the model predicts all true positives correctly; it also predicts the maximum number of false positives, as the entire orange distribution is located to the right of the boundary. As the boundary slides rightwards, the number of false positives decreases as the boundary slides over the orange distribution; the number of true positives is still at maximum.</p>

<p>At some point, the boundary will start sliding over the blue distribution. As this happens, the number of true positives decreases, until eventually the boundary is entirely to the right of all the data. Then, both the number of false positives as well as true positives is zero.</p>

<p>The curve traced out from the point (1,1) to (0,0) is known as the receiver operating characteristic, or ROC curve. As you can see in the following examples, the ROC curve depends on the shape of the data distribution (in general it is also a function of the model). If the data is on top of each other, no decision boundary will be able to discriminate between true and false values; the ROC curve is a straight y=x line. If the data is cleanly separated, the curve forms a sharp right angle.</p>

<p>A more optimal classifier has an ROC curve closer to the right angle. It turns out that the corresponding metric which is maximised is the area under the curve, or AUC.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">nsamplestrue</span>  <span class="o">=</span> <span class="mi">2500</span>
<span class="n">nsamplesfalse</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">mean</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">distA</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nsamplestrue</span><span class="p">)</span><span class="o">+</span><span class="n">mean</span>
<span class="n">distB</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nsamplesfalse</span><span class="p">)</span><span class="o">-</span><span class="n">mean</span>
<span class="n">decisionboundary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span> <span class="c"># Move the decision boundary around</span>
<span class="n">truepositives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">distA</span> <span class="o">&gt;</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">decisionboundary</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">truenegatives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">distB</span> <span class="o">&lt;</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">decisionboundary</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">falsepositives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">distB</span> <span class="o">&gt;</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">decisionboundary</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">falsenegatives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">distA</span> <span class="o">&lt;</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">decisionboundary</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">distA</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">distB</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Counts'</span><span class="p">);</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">falsepositives</span><span class="o">/</span><span class="n">nsamplesfalse</span><span class="p">,</span> <span class="n">truepositives</span><span class="o">/</span><span class="n">nsamplestrue</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'ROC'</span><span class="p">);</span>   
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'True positive rate'</span><span class="p">);</span> 
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span> <span class="p">;</span> 

<span class="n">mean</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">distA</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nsamplestrue</span><span class="p">)</span><span class="o">+</span><span class="n">mean</span>
<span class="n">distB</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nsamplesfalse</span><span class="p">)</span><span class="o">-</span><span class="n">mean</span>
<span class="n">decisionboundary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span> <span class="c"># Move the decision boundary around</span>
<span class="n">truepositives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">distA</span> <span class="o">&gt;</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">decisionboundary</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">truenegatives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">distB</span> <span class="o">&lt;</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">decisionboundary</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">falsepositives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">distB</span> <span class="o">&gt;</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">decisionboundary</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">falsenegatives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">distA</span> <span class="o">&lt;</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">decisionboundary</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">distA</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">distB</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Counts'</span><span class="p">);</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">falsepositives</span><span class="o">/</span><span class="n">nsamplesfalse</span><span class="p">,</span> <span class="n">truepositives</span><span class="o">/</span><span class="n">nsamplestrue</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'ROC'</span><span class="p">);</span>  
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'True positive rate'</span><span class="p">);</span> 
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> 

<span class="n">mean</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">distA</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nsamplestrue</span><span class="p">)</span><span class="o">+</span><span class="n">mean</span>
<span class="n">distB</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nsamplesfalse</span><span class="p">)</span><span class="o">-</span><span class="n">mean</span>
<span class="n">decisionboundary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span> <span class="c"># Move the decision boundary around</span>
<span class="n">truepositives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">distA</span> <span class="o">&gt;</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">decisionboundary</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">truenegatives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">distB</span> <span class="o">&lt;</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">decisionboundary</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">falsepositives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">distB</span> <span class="o">&gt;</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">decisionboundary</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">falsenegatives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">distA</span> <span class="o">&lt;</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">decisionboundary</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">distA</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">distB</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Coordinate'</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Counts'</span><span class="p">);</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">falsepositives</span><span class="o">/</span><span class="n">nsamplesfalse</span><span class="p">,</span> <span class="n">truepositives</span><span class="o">/</span><span class="n">nsamplestrue</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'ROC'</span><span class="p">);</span>  
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'False positive rate'</span><span class="p">);</span>  
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'True positive rate'</span><span class="p">);</span> 
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> 

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="/assets/images/MBC_23_0.png" width="500" alt="me" align="center" hspace="40" vspace="40" /></p>

<hr />

<h3 id="3-conclusions">3. Conclusions</h3>

<p>conclusions</p>

<p>A jupyter notebook is available for this tutorial on my <a href="https://github.com/nadanai263/datasciportfolio">GitHub repository</a>.</p>

    </div>

    

    

    <hr>
    <div class="pagination">
      <ul>
      
        <li class="prev"><a href="/2018/11/21/Hello-Tensorflow" title="Hello Tensorflow: what is Tensorflow and how do I use it for machine learning?">&larr; Previous</a></li>
      
        <li><a href="/pages/projects.html">Archive</a></li>
      
        <li class="next"><a href="/2018/11/26/Cross-validation" title="Cross-validation">Next &rarr;</a></li>
      
      </ul>
    </div>
    <hr>
    
  </div>
</div>


      </div>
      <hr>
      <footer>
        <p><small>
  <!-- start of Karl's footer; modify this part -->
          <a href="https://creativecommons.org/publicdomain/zero/1.0/"><img src="https://i.creativecommons.org/p/zero/1.0/88x31.png" alt="CC0"/></a> &nbsp;
          <a href="http://nadanai263.github.io/">Nadanai Laohakunakorn</a>
  <!-- end of Karl's footer; modify this part -->
        </small></p>
      </footer>

    </div>

    
  </body>
</html>

